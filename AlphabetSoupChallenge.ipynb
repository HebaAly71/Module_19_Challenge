{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EIN</th>\n",
       "      <th>NAME</th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10520599</td>\n",
       "      <td>BLUE KNIGHTS MOTORCYCLE CLUB</td>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10531628</td>\n",
       "      <td>AMERICAN CHESAPEAKE CLUB CHARITABLE TR</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10547893</td>\n",
       "      <td>ST CLOUD PROFESSIONAL FIREFIGHTERS</td>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10553066</td>\n",
       "      <td>SOUTHSIDE ATHLETIC ASSOCIATION</td>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10556103</td>\n",
       "      <td>GENETIC RESEARCH INSTITUTE OF THE DESERT</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        EIN                                      NAME APPLICATION_TYPE  \\\n",
       "0  10520599              BLUE KNIGHTS MOTORCYCLE CLUB              T10   \n",
       "1  10531628    AMERICAN CHESAPEAKE CLUB CHARITABLE TR               T3   \n",
       "2  10547893        ST CLOUD PROFESSIONAL FIREFIGHTERS               T5   \n",
       "3  10553066            SOUTHSIDE ATHLETIC ASSOCIATION               T3   \n",
       "4  10556103  GENETIC RESEARCH INSTITUTE OF THE DESERT               T3   \n",
       "\n",
       "        AFFILIATION CLASSIFICATION      USE_CASE  ORGANIZATION  STATUS  \\\n",
       "0       Independent          C1000    ProductDev   Association       1   \n",
       "1       Independent          C2000  Preservation  Co-operative       1   \n",
       "2  CompanySponsored          C3000    ProductDev   Association       1   \n",
       "3  CompanySponsored          C2000  Preservation         Trust       1   \n",
       "4       Independent          C1000     Heathcare         Trust       1   \n",
       "\n",
       "      INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  IS_SUCCESSFUL  \n",
       "0              0                      N     5000              1  \n",
       "1         1-9999                      N   108590              1  \n",
       "2              0                      N     5000              0  \n",
       "3    10000-24999                      N     6692              1  \n",
       "4  100000-499999                      N   142590              1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "# Import our input dataset\n",
    "success_df = pd.read_csv('charity_data.csv')\n",
    "success_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate our categorical variable list\n",
    "success_cat = success_df.dtypes[success_df.dtypes == \"object\"].index.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NAME                      19568\n",
       "APPLICATION_TYPE             17\n",
       "AFFILIATION                   6\n",
       "CLASSIFICATION               71\n",
       "USE_CASE                      5\n",
       "ORGANIZATION                  4\n",
       "INCOME_AMT                    9\n",
       "SPECIAL_CONSIDERATIONS        2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of unique values in each column\n",
    "success_df[success_cat].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EIN</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10520599</td>\n",
       "      <td>Independent</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10531628</td>\n",
       "      <td>Independent</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10547893</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10553066</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10556103</td>\n",
       "      <td>Independent</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34294</th>\n",
       "      <td>996009318</td>\n",
       "      <td>Independent</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34295</th>\n",
       "      <td>996010315</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34296</th>\n",
       "      <td>996012607</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34297</th>\n",
       "      <td>996015768</td>\n",
       "      <td>Independent</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34298</th>\n",
       "      <td>996086871</td>\n",
       "      <td>Independent</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1M-5M</td>\n",
       "      <td>N</td>\n",
       "      <td>36500179</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34299 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             EIN       AFFILIATION      USE_CASE  ORGANIZATION  STATUS  \\\n",
       "0       10520599       Independent    ProductDev   Association       1   \n",
       "1       10531628       Independent  Preservation  Co-operative       1   \n",
       "2       10547893  CompanySponsored    ProductDev   Association       1   \n",
       "3       10553066  CompanySponsored  Preservation         Trust       1   \n",
       "4       10556103       Independent     Heathcare         Trust       1   \n",
       "...          ...               ...           ...           ...     ...   \n",
       "34294  996009318       Independent    ProductDev   Association       1   \n",
       "34295  996010315  CompanySponsored    ProductDev   Association       1   \n",
       "34296  996012607  CompanySponsored  Preservation   Association       1   \n",
       "34297  996015768       Independent    ProductDev   Association       1   \n",
       "34298  996086871       Independent  Preservation  Co-operative       1   \n",
       "\n",
       "          INCOME_AMT SPECIAL_CONSIDERATIONS   ASK_AMT  IS_SUCCESSFUL  \n",
       "0                  0                      N      5000              1  \n",
       "1             1-9999                      N    108590              1  \n",
       "2                  0                      N      5000              0  \n",
       "3        10000-24999                      N      6692              1  \n",
       "4      100000-499999                      N    142590              1  \n",
       "...              ...                    ...       ...            ...  \n",
       "34294              0                      N      5000              0  \n",
       "34295              0                      N      5000              0  \n",
       "34296              0                      N      5000              0  \n",
       "34297              0                      N      5000              1  \n",
       "34298          1M-5M                      N  36500179              0  \n",
       "\n",
       "[34299 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop name classification and application type columns since they are irrelevant to our analysis\n",
    "success_df = success_df.drop(['CLASSIFICATION','APPLICATION_TYPE','NAME'], axis='columns')\n",
    "success_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate our categorical variable list\n",
    "success_cat = success_df.dtypes[success_df.dtypes == \"object\"].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AFFILIATION               6\n",
       "USE_CASE                  5\n",
       "ORGANIZATION              4\n",
       "INCOME_AMT                9\n",
       "SPECIAL_CONSIDERATIONS    2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of unique values in each column\n",
    "success_df[success_cat].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AFFILIATION_CompanySponsored</th>\n",
       "      <th>AFFILIATION_Family/Parent</th>\n",
       "      <th>AFFILIATION_Independent</th>\n",
       "      <th>AFFILIATION_National</th>\n",
       "      <th>AFFILIATION_Other</th>\n",
       "      <th>AFFILIATION_Regional</th>\n",
       "      <th>USE_CASE_CommunityServ</th>\n",
       "      <th>USE_CASE_Heathcare</th>\n",
       "      <th>USE_CASE_Other</th>\n",
       "      <th>USE_CASE_Preservation</th>\n",
       "      <th>...</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AFFILIATION_CompanySponsored  AFFILIATION_Family/Parent  \\\n",
       "0                           0.0                        0.0   \n",
       "1                           0.0                        0.0   \n",
       "2                           1.0                        0.0   \n",
       "3                           1.0                        0.0   \n",
       "4                           0.0                        0.0   \n",
       "\n",
       "   AFFILIATION_Independent  AFFILIATION_National  AFFILIATION_Other  \\\n",
       "0                      1.0                   0.0                0.0   \n",
       "1                      1.0                   0.0                0.0   \n",
       "2                      0.0                   0.0                0.0   \n",
       "3                      0.0                   0.0                0.0   \n",
       "4                      1.0                   0.0                0.0   \n",
       "\n",
       "   AFFILIATION_Regional  USE_CASE_CommunityServ  USE_CASE_Heathcare  \\\n",
       "0                   0.0                     0.0                 0.0   \n",
       "1                   0.0                     0.0                 0.0   \n",
       "2                   0.0                     0.0                 0.0   \n",
       "3                   0.0                     0.0                 0.0   \n",
       "4                   0.0                     0.0                 1.0   \n",
       "\n",
       "   USE_CASE_Other  USE_CASE_Preservation  ...  INCOME_AMT_1-9999  \\\n",
       "0             0.0                    0.0  ...                0.0   \n",
       "1             0.0                    1.0  ...                1.0   \n",
       "2             0.0                    0.0  ...                0.0   \n",
       "3             0.0                    1.0  ...                0.0   \n",
       "4             0.0                    0.0  ...                0.0   \n",
       "\n",
       "   INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  INCOME_AMT_10M-50M  \\\n",
       "0                     0.0                       0.0                 0.0   \n",
       "1                     0.0                       0.0                 0.0   \n",
       "2                     0.0                       0.0                 0.0   \n",
       "3                     1.0                       0.0                 0.0   \n",
       "4                     0.0                       1.0                 0.0   \n",
       "\n",
       "   INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  INCOME_AMT_50M+  \\\n",
       "0               0.0                     0.0              0.0   \n",
       "1               0.0                     0.0              0.0   \n",
       "2               0.0                     0.0              0.0   \n",
       "3               0.0                     0.0              0.0   \n",
       "4               0.0                     0.0              0.0   \n",
       "\n",
       "   INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_N  SPECIAL_CONSIDERATIONS_Y  \n",
       "0                0.0                       1.0                       0.0  \n",
       "1                0.0                       1.0                       0.0  \n",
       "2                0.0                       1.0                       0.0  \n",
       "3                0.0                       1.0                       0.0  \n",
       "4                0.0                       1.0                       0.0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a OneHotEncoder instance\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Fit and transform the OneHotEncoder using the categorical variable list\n",
    "encode_df = pd.DataFrame(enc.fit_transform(success_df[success_cat]))\n",
    "\n",
    "# Add the encoded variable names to the DataFrame\n",
    "encode_df.columns = enc.get_feature_names(success_cat)\n",
    "encode_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EIN</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "      <th>AFFILIATION_CompanySponsored</th>\n",
       "      <th>AFFILIATION_Family/Parent</th>\n",
       "      <th>AFFILIATION_Independent</th>\n",
       "      <th>AFFILIATION_National</th>\n",
       "      <th>AFFILIATION_Other</th>\n",
       "      <th>AFFILIATION_Regional</th>\n",
       "      <th>...</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10520599</td>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10531628</td>\n",
       "      <td>1</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10547893</td>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10553066</td>\n",
       "      <td>1</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10556103</td>\n",
       "      <td>1</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        EIN  STATUS  ASK_AMT  IS_SUCCESSFUL  AFFILIATION_CompanySponsored  \\\n",
       "0  10520599       1     5000              1                           0.0   \n",
       "1  10531628       1   108590              1                           0.0   \n",
       "2  10547893       1     5000              0                           1.0   \n",
       "3  10553066       1     6692              1                           1.0   \n",
       "4  10556103       1   142590              1                           0.0   \n",
       "\n",
       "   AFFILIATION_Family/Parent  AFFILIATION_Independent  AFFILIATION_National  \\\n",
       "0                        0.0                      1.0                   0.0   \n",
       "1                        0.0                      1.0                   0.0   \n",
       "2                        0.0                      0.0                   0.0   \n",
       "3                        0.0                      0.0                   0.0   \n",
       "4                        0.0                      1.0                   0.0   \n",
       "\n",
       "   AFFILIATION_Other  AFFILIATION_Regional  ...  INCOME_AMT_1-9999  \\\n",
       "0                0.0                   0.0  ...                0.0   \n",
       "1                0.0                   0.0  ...                1.0   \n",
       "2                0.0                   0.0  ...                0.0   \n",
       "3                0.0                   0.0  ...                0.0   \n",
       "4                0.0                   0.0  ...                0.0   \n",
       "\n",
       "   INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  INCOME_AMT_10M-50M  \\\n",
       "0                     0.0                       0.0                 0.0   \n",
       "1                     0.0                       0.0                 0.0   \n",
       "2                     0.0                       0.0                 0.0   \n",
       "3                     1.0                       0.0                 0.0   \n",
       "4                     0.0                       1.0                 0.0   \n",
       "\n",
       "   INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  INCOME_AMT_50M+  \\\n",
       "0               0.0                     0.0              0.0   \n",
       "1               0.0                     0.0              0.0   \n",
       "2               0.0                     0.0              0.0   \n",
       "3               0.0                     0.0              0.0   \n",
       "4               0.0                     0.0              0.0   \n",
       "\n",
       "   INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_N  SPECIAL_CONSIDERATIONS_Y  \n",
       "0                0.0                       1.0                       0.0  \n",
       "1                0.0                       1.0                       0.0  \n",
       "2                0.0                       1.0                       0.0  \n",
       "3                0.0                       1.0                       0.0  \n",
       "4                0.0                       1.0                       0.0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge one-hot encoded features and drop the originals\n",
    "success_df = success_df.merge(encode_df,left_index=True, right_index=True)\n",
    "success_df = success_df.drop(success_cat,1)\n",
    "success_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = success_df[\"IS_SUCCESSFUL\"].values\n",
    "X = success_df.drop([\"IS_SUCCESSFUL\"],1).values\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_25 (Dense)             (None, 8)                 240       \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 5)                 45        \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 291\n",
      "Trainable params: 291\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 =  8\n",
    "hidden_nodes_layer2 = 5\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\")\n",
    ")\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25724 samples\n",
      "Epoch 1/100\n",
      "25724/25724 [==============================] - 5s 176us/sample - loss: 1793855.1141 - accuracy: 0.5052\n",
      "Epoch 2/100\n",
      "25724/25724 [==============================] - 3s 107us/sample - loss: 8279.0872 - accuracy: 0.5067\n",
      "Epoch 3/100\n",
      "25724/25724 [==============================] - 3s 112us/sample - loss: 12755.2037 - accuracy: 0.5038\n",
      "Epoch 4/100\n",
      "25724/25724 [==============================] - 3s 110us/sample - loss: 12672.4297 - accuracy: 0.5331\n",
      "Epoch 5/100\n",
      "25724/25724 [==============================] - 3s 106us/sample - loss: 12195.9627 - accuracy: 0.5332\n",
      "Epoch 6/100\n",
      "25724/25724 [==============================] - 3s 108us/sample - loss: 2250.3295 - accuracy: 0.5327\n",
      "Epoch 7/100\n",
      "25724/25724 [==============================] - 3s 111us/sample - loss: 12791.6798 - accuracy: 0.5324\n",
      "Epoch 8/100\n",
      "25724/25724 [==============================] - 3s 117us/sample - loss: 4147.4413 - accuracy: 0.5326s - loss\n",
      "Epoch 9/100\n",
      "25724/25724 [==============================] - 3s 126us/sample - loss: 4714.6456 - accuracy: 0.5323\n",
      "Epoch 10/100\n",
      "25724/25724 [==============================] - 3s 124us/sample - loss: 5.8958 - accuracy: 0.5323\n",
      "Epoch 11/100\n",
      "25724/25724 [==============================] - 3s 115us/sample - loss: 3.7763 - accuracy: 0.5322\n",
      "Epoch 12/100\n",
      "25724/25724 [==============================] - 3s 112us/sample - loss: 1.2157 - accuracy: 0.5323\n",
      "Epoch 13/100\n",
      "25724/25724 [==============================] - 3s 112us/sample - loss: 0.7918 - accuracy: 0.5321\n",
      "Epoch 14/100\n",
      "25724/25724 [==============================] - 3s 111us/sample - loss: 0.6910 - accuracy: 0.5321\n",
      "Epoch 15/100\n",
      "25724/25724 [==============================] - 3s 134us/sample - loss: 0.6910 - accuracy: 0.5321\n",
      "Epoch 16/100\n",
      "25724/25724 [==============================] - 3s 130us/sample - loss: 0.6910 - accuracy: 0.5321\n",
      "Epoch 17/100\n",
      "25724/25724 [==============================] - 3s 117us/sample - loss: 0.6910 - accuracy: 0.5321\n",
      "Epoch 18/100\n",
      "25724/25724 [==============================] - 3s 123us/sample - loss: 0.6910 - accuracy: 0.5321\n",
      "Epoch 19/100\n",
      "25724/25724 [==============================] - 3s 123us/sample - loss: 0.6910 - accuracy: 0.5321\n",
      "Epoch 20/100\n",
      "25724/25724 [==============================] - 3s 115us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 21/100\n",
      "25724/25724 [==============================] - 3s 107us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 22/100\n",
      "25724/25724 [==============================] - 3s 110us/sample - loss: 0.6910 - accuracy: 0.5321\n",
      "Epoch 23/100\n",
      "25724/25724 [==============================] - 3s 125us/sample - loss: 0.6910 - accuracy: 0.5321\n",
      "Epoch 24/100\n",
      "25724/25724 [==============================] - 4s 147us/sample - loss: 0.6910 - accuracy: 0.5321\n",
      "Epoch 25/100\n",
      "25724/25724 [==============================] - 3s 116us/sample - loss: 0.6910 - accuracy: 0.5321\n",
      "Epoch 26/100\n",
      "25724/25724 [==============================] - 4s 151us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 27/100\n",
      "25724/25724 [==============================] - 4s 142us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 28/100\n",
      "25724/25724 [==============================] - 3s 126us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 29/100\n",
      "25724/25724 [==============================] - 4s 137us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 30/100\n",
      "25724/25724 [==============================] - 4s 143us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 31/100\n",
      "25724/25724 [==============================] - 4s 144us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 32/100\n",
      "25724/25724 [==============================] - 3s 111us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 33/100\n",
      "25724/25724 [==============================] - 3s 129us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 34/100\n",
      "25724/25724 [==============================] - 3s 127us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 35/100\n",
      "25724/25724 [==============================] - 4s 157us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 36/100\n",
      "25724/25724 [==============================] - 4s 152us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 37/100\n",
      "25724/25724 [==============================] - 4s 160us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 38/100\n",
      "25724/25724 [==============================] - 4s 157us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 39/100\n",
      "25724/25724 [==============================] - 5s 186us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 40/100\n",
      "25724/25724 [==============================] - 3s 123us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 41/100\n",
      "25724/25724 [==============================] - 3s 112us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 42/100\n",
      "25724/25724 [==============================] - 3s 108us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 43/100\n",
      "25724/25724 [==============================] - 3s 113us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 44/100\n",
      "25724/25724 [==============================] - 3s 111us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 45/100\n",
      "25724/25724 [==============================] - 3s 114us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 46/100\n",
      "25724/25724 [==============================] - 3s 125us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 47/100\n",
      "25724/25724 [==============================] - 3s 115us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 48/100\n",
      "25724/25724 [==============================] - 3s 108us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 49/100\n",
      "25724/25724 [==============================] - 3s 110us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 50/100\n",
      "25724/25724 [==============================] - 3s 112us/sample - loss: 0.6911 - accuracy: 0.5321 - loss: 0.6911 - accuracy: \n",
      "Epoch 51/100\n",
      "25724/25724 [==============================] - 3s 110us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 52/100\n",
      "25724/25724 [==============================] - 3s 125us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 53/100\n",
      "25724/25724 [==============================] - 3s 124us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 54/100\n",
      "25724/25724 [==============================] - 3s 130us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 55/100\n",
      "25724/25724 [==============================] - 3s 122us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 56/100\n",
      "25724/25724 [==============================] - 3s 112us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 57/100\n",
      "25724/25724 [==============================] - 3s 112us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 58/100\n",
      "25724/25724 [==============================] - 3s 130us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 59/100\n",
      "25724/25724 [==============================] - 3s 111us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 60/100\n",
      "25724/25724 [==============================] - 3s 127us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 61/100\n",
      "17472/25724 [===================>..........] - ETA: 0s - loss: 0.6909 - accuracy: 0.5336"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-e97c953b5797>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfit_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    534\u001b[0m   return pack_sequence_as(\n\u001b[1;32m    535\u001b[0m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 536\u001b[0;31m       expand_composites=expand_composites)\n\u001b[0m\u001b[1;32m    537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/util/nest.py\u001b[0m in \u001b[0;36mpack_sequence_as\u001b[0;34m(structure, flat_sequence, expand_composites)\u001b[0m\n\u001b[1;32m    459\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m     final_index, packed = _packed_nest_with_indices(structure, flat_sequence,\n\u001b[0;32m--> 461\u001b[0;31m                                                     0, is_seq)\n\u001b[0m\u001b[1;32m    462\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_index\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_sequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/util/nest.py\u001b[0m in \u001b[0;36m_packed_nest_with_indices\u001b[0;34m(structure, flat, index, is_seq)\u001b[0m\n\u001b[1;32m    403\u001b[0m   \"\"\"\n\u001b[1;32m    404\u001b[0m   \u001b[0mpacked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_yield_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m       \u001b[0mnew_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_packed_nest_with_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train,y_train,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8575/1 - 1s - loss: 0.6899 - accuracy: 0.5332\n",
      "Loss: 0.6909440315916656, Accuracy: 0.5331778526306152\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempts to improve model:\n",
    "#### 1) Increase number of hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 8)                 448       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 5)                 45        \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 529\n",
      "Trainable params: 529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 =  8\n",
    "hidden_nodes_layer2 = 5\n",
    "hidden_nodes_layer3 = 5\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\")\n",
    ")\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# third hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"relu\"))\n",
    "\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25724 samples\n",
      "Epoch 1/100\n",
      "25724/25724 [==============================] - 4s 166us/sample - loss: 832571.5857 - accuracy: 0.5163\n",
      "Epoch 2/100\n",
      "25724/25724 [==============================] - 3s 111us/sample - loss: 35879.0141 - accuracy: 0.5326\n",
      "Epoch 3/100\n",
      "25724/25724 [==============================] - 3s 111us/sample - loss: 11631.6435 - accuracy: 0.5326\n",
      "Epoch 4/100\n",
      "25724/25724 [==============================] - 3s 112us/sample - loss: 2086.7635 - accuracy: 0.5322\n",
      "Epoch 5/100\n",
      "25724/25724 [==============================] - 3s 110us/sample - loss: 416.7635 - accuracy: 0.5323\n",
      "Epoch 6/100\n",
      "25724/25724 [==============================] - 3s 118us/sample - loss: 27.3453 - accuracy: 0.5323\n",
      "Epoch 7/100\n",
      "25724/25724 [==============================] - 3s 115us/sample - loss: 14.6903 - accuracy: 0.5325\n",
      "Epoch 8/100\n",
      "25724/25724 [==============================] - 4s 169us/sample - loss: 8.1432 - accuracy: 0.5325\n",
      "Epoch 9/100\n",
      "25724/25724 [==============================] - 3s 133us/sample - loss: 0.9518 - accuracy: 0.5324\n",
      "Epoch 10/100\n",
      "25724/25724 [==============================] - 4s 136us/sample - loss: 0.7254 - accuracy: 0.5322\n",
      "Epoch 11/100\n",
      "25724/25724 [==============================] - 3s 117us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 12/100\n",
      "25724/25724 [==============================] - 3s 125us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 13/100\n",
      "25724/25724 [==============================] - 4s 144us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 14/100\n",
      "25724/25724 [==============================] - 4s 173us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 15/100\n",
      "25724/25724 [==============================] - 4s 174us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 16/100\n",
      "25724/25724 [==============================] - 4s 155us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 17/100\n",
      "25724/25724 [==============================] - 4s 144us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 18/100\n",
      "25724/25724 [==============================] - 4s 158us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 19/100\n",
      "25724/25724 [==============================] - 4s 173us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 20/100\n",
      "25724/25724 [==============================] - 3s 122us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 21/100\n",
      "25724/25724 [==============================] - 3s 110us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 22/100\n",
      "25724/25724 [==============================] - 3s 115us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 23/100\n",
      "25724/25724 [==============================] - 3s 110us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 24/100\n",
      "25724/25724 [==============================] - 3s 113us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 25/100\n",
      "25724/25724 [==============================] - 4s 171us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 26/100\n",
      "25724/25724 [==============================] - 4s 172us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 27/100\n",
      "25724/25724 [==============================] - 4s 161us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 28/100\n",
      "25724/25724 [==============================] - 3s 116us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 29/100\n",
      "25724/25724 [==============================] - 3s 123us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 30/100\n",
      "25724/25724 [==============================] - 4s 158us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 31/100\n",
      "25724/25724 [==============================] - 3s 134us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 32/100\n",
      "25724/25724 [==============================] - 4s 153us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 33/100\n",
      "25724/25724 [==============================] - 4s 148us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 34/100\n",
      "25724/25724 [==============================] - 4s 153us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 35/100\n",
      "25724/25724 [==============================] - 3s 120us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 36/100\n",
      "25724/25724 [==============================] - 3s 130us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 37/100\n",
      "25724/25724 [==============================] - 3s 134us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 38/100\n",
      "25724/25724 [==============================] - 3s 130us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 39/100\n",
      "25724/25724 [==============================] - 3s 116us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 40/100\n",
      "25724/25724 [==============================] - 3s 120us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 41/100\n",
      "25724/25724 [==============================] - 3s 122us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 42/100\n",
      "25724/25724 [==============================] - 3s 124us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 43/100\n",
      "25724/25724 [==============================] - 3s 129us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 44/100\n",
      "25724/25724 [==============================] - 4s 171us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 45/100\n",
      "25724/25724 [==============================] - 4s 158us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 46/100\n",
      "25724/25724 [==============================] - 3s 109us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 47/100\n",
      "25724/25724 [==============================] - 4s 159us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 48/100\n",
      "25724/25724 [==============================] - 4s 153us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 49/100\n",
      "25724/25724 [==============================] - 3s 132us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 50/100\n",
      "25724/25724 [==============================] - 3s 132us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 51/100\n",
      "25724/25724 [==============================] - 4s 164us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 52/100\n",
      "25724/25724 [==============================] - 3s 129us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 53/100\n",
      "25724/25724 [==============================] - 3s 104us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 54/100\n",
      "25724/25724 [==============================] - 3s 128us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 55/100\n",
      "25724/25724 [==============================] - 3s 107us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 56/100\n",
      "25724/25724 [==============================] - 3s 106us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 57/100\n",
      "25724/25724 [==============================] - 3s 108us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 58/100\n",
      "25724/25724 [==============================] - 3s 110us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 59/100\n",
      "25724/25724 [==============================] - 3s 113us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 60/100\n",
      "25724/25724 [==============================] - 3s 124us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 61/100\n",
      "25724/25724 [==============================] - 3s 114us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 62/100\n",
      "25724/25724 [==============================] - 3s 110us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 63/100\n",
      "25724/25724 [==============================] - 4s 140us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 64/100\n",
      "25724/25724 [==============================] - 4s 152us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 65/100\n",
      "25724/25724 [==============================] - 3s 120us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 66/100\n",
      "25724/25724 [==============================] - 3s 110us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 67/100\n",
      "25724/25724 [==============================] - 5s 181us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 68/100\n",
      "25724/25724 [==============================] - 3s 109us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 69/100\n",
      "25724/25724 [==============================] - 3s 107us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 70/100\n",
      "25724/25724 [==============================] - 4s 143us/sample - loss: 0.6911 - accuracy: 0.5321 - loss: 0.6911 - accuracy\n",
      "Epoch 71/100\n",
      "25724/25724 [==============================] - 3s 107us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 72/100\n",
      "25724/25724 [==============================] - 3s 125us/sample - loss: 0.6911 - accuracy: 0.5321 - l\n",
      "Epoch 73/100\n",
      "25724/25724 [==============================] - 3s 110us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 74/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25724/25724 [==============================] - 3s 122us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 75/100\n",
      "25724/25724 [==============================] - 3s 113us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 76/100\n",
      "25724/25724 [==============================] - 3s 113us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 77/100\n",
      "25724/25724 [==============================] - 3s 125us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 78/100\n",
      "25724/25724 [==============================] - 3s 132us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 79/100\n",
      "25724/25724 [==============================] - 3s 107us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 80/100\n",
      "25724/25724 [==============================] - 4s 140us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 81/100\n",
      "25724/25724 [==============================] - 4s 140us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 82/100\n",
      "25724/25724 [==============================] - 3s 126us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 83/100\n",
      "25724/25724 [==============================] - 3s 131us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 84/100\n",
      "25724/25724 [==============================] - 4s 149us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 85/100\n",
      "25724/25724 [==============================] - 4s 164us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 86/100\n",
      "25724/25724 [==============================] - 3s 123us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 87/100\n",
      "25724/25724 [==============================] - 4s 145us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 88/100\n",
      "25724/25724 [==============================] - 5s 185us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 89/100\n",
      "25724/25724 [==============================] - 4s 166us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 90/100\n",
      "25724/25724 [==============================] - 3s 118us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 91/100\n",
      "25724/25724 [==============================] - 3s 127us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 92/100\n",
      "25724/25724 [==============================] - 3s 114us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 93/100\n",
      "25724/25724 [==============================] - 3s 136us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 94/100\n",
      "25724/25724 [==============================] - 3s 129us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 95/100\n",
      "25724/25724 [==============================] - 3s 115us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 96/100\n",
      "25724/25724 [==============================] - 3s 115us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 97/100\n",
      "25724/25724 [==============================] - 3s 120us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 98/100\n",
      "25724/25724 [==============================] - 3s 115us/sample - loss: 0.6911 - accuracy: 0.5321 ETA: 0s - l\n",
      "Epoch 99/100\n",
      "25724/25724 [==============================] - 3s 115us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 100/100\n",
      "25724/25724 [==============================] - 4s 161us/sample - loss: 0.6911 - accuracy: 0.5321\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train,y_train,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8575/1 - 1s - loss: 0.6899 - accuracy: 0.5332\n",
      "Loss: 0.6909442992252094, Accuracy: 0.5331778526306152\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By increasing the number of hidden layers both the accuracy and the loss is exactly the same as our original model, with an accuracy of 53.3% and a loss of 0.691."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Increasing number of neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 58)                1740      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 472       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 2,221\n",
      "Trainable params: 2,221\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 =  len(X_train[0])*2\n",
    "hidden_nodes_layer2 = 8\n",
    "#hidden_nodes_layer3 = 5\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\")\n",
    ")\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# third hidden layer\n",
    "#nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"relu\"))\n",
    "\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25724 samples\n",
      "Epoch 1/100\n",
      "25724/25724 [==============================] - 4s 167us/sample - loss: 629342.5156 - accuracy: 0.5068\n",
      "Epoch 2/100\n",
      "25724/25724 [==============================] - 3s 111us/sample - loss: 456783.1514 - accuracy: 0.5037\n",
      "Epoch 3/100\n",
      "25724/25724 [==============================] - 3s 107us/sample - loss: 442614.2153 - accuracy: 0.5025\n",
      "Epoch 4/100\n",
      "25724/25724 [==============================] - 3s 107us/sample - loss: 385963.4700 - accuracy: 0.5037\n",
      "Epoch 5/100\n",
      "25724/25724 [==============================] - 3s 109us/sample - loss: 351615.0079 - accuracy: 0.5036\n",
      "Epoch 6/100\n",
      "25724/25724 [==============================] - 4s 138us/sample - loss: 356192.6856 - accuracy: 0.5038\n",
      "Epoch 7/100\n",
      "25724/25724 [==============================] - 4s 139us/sample - loss: 355989.1504 - accuracy: 0.5070\n",
      "Epoch 8/100\n",
      "25724/25724 [==============================] - 3s 112us/sample - loss: 334954.0480 - accuracy: 0.5037\n",
      "Epoch 9/100\n",
      "25724/25724 [==============================] - 3s 101us/sample - loss: 289174.6954 - accuracy: 0.5031\n",
      "Epoch 10/100\n",
      "25724/25724 [==============================] - 3s 105us/sample - loss: 308787.0886 - accuracy: 0.4997\n",
      "Epoch 11/100\n",
      "25724/25724 [==============================] - 3s 109us/sample - loss: 280200.3244 - accuracy: 0.4963\n",
      "Epoch 12/100\n",
      "25724/25724 [==============================] - 4s 143us/sample - loss: 270066.0505 - accuracy: 0.5059\n",
      "Epoch 13/100\n",
      "25724/25724 [==============================] - 3s 114us/sample - loss: 233594.5276 - accuracy: 0.5003\n",
      "Epoch 14/100\n",
      "25724/25724 [==============================] - 3s 102us/sample - loss: 250060.3396 - accuracy: 0.4979\n",
      "Epoch 15/100\n",
      "25724/25724 [==============================] - 5s 188us/sample - loss: 205749.5107 - accuracy: 0.5047\n",
      "Epoch 16/100\n",
      "25724/25724 [==============================] - 5s 189us/sample - loss: 202599.4316 - accuracy: 0.5035\n",
      "Epoch 17/100\n",
      "25724/25724 [==============================] - 5s 183us/sample - loss: 174274.1482 - accuracy: 0.5007s - loss: 185908.9369 - a\n",
      "Epoch 18/100\n",
      "25724/25724 [==============================] - 6s 230us/sample - loss: 199899.1181 - accuracy: 0.5004\n",
      "Epoch 19/100\n",
      "25724/25724 [==============================] - 4s 139us/sample - loss: 177260.4186 - accuracy: 0.5007\n",
      "Epoch 20/100\n",
      "25724/25724 [==============================] - 4s 138us/sample - loss: 149404.7524 - accuracy: 0.4989\n",
      "Epoch 21/100\n",
      "25724/25724 [==============================] - 3s 114us/sample - loss: 149067.8802 - accuracy: 0.5027\n",
      "Epoch 22/100\n",
      "25724/25724 [==============================] - 3s 114us/sample - loss: 157467.5563 - accuracy: 0.4958\n",
      "Epoch 23/100\n",
      "25724/25724 [==============================] - 3s 109us/sample - loss: 131083.5809 - accuracy: 0.5061s - loss: 150764.65\n",
      "Epoch 24/100\n",
      "25724/25724 [==============================] - 3s 113us/sample - loss: 106337.2678 - accuracy: 0.5020\n",
      "Epoch 25/100\n",
      "25724/25724 [==============================] - 3s 135us/sample - loss: 114669.0180 - accuracy: 0.4983\n",
      "Epoch 26/100\n",
      "25724/25724 [==============================] - 3s 125us/sample - loss: 126855.9078 - accuracy: 0.5005\n",
      "Epoch 27/100\n",
      "25724/25724 [==============================] - 4s 161us/sample - loss: 99039.4941 - accuracy: 0.5002\n",
      "Epoch 28/100\n",
      "25724/25724 [==============================] - 4s 139us/sample - loss: 102488.9727 - accuracy: 0.5072\n",
      "Epoch 29/100\n",
      "25724/25724 [==============================] - 3s 115us/sample - loss: 91833.4691 - accuracy: 0.5006\n",
      "Epoch 30/100\n",
      "25724/25724 [==============================] - 4s 153us/sample - loss: 87667.9814 - accuracy: 0.5014\n",
      "Epoch 31/100\n",
      "25724/25724 [==============================] - 4s 160us/sample - loss: 82689.0051 - accuracy: 0.4995\n",
      "Epoch 32/100\n",
      "25724/25724 [==============================] - 5s 193us/sample - loss: 66251.6849 - accuracy: 0.4958\n",
      "Epoch 33/100\n",
      "25724/25724 [==============================] - 6s 215us/sample - loss: 66232.8910 - accuracy: 0.5012\n",
      "Epoch 34/100\n",
      "25724/25724 [==============================] - 4s 169us/sample - loss: 23074.3339 - accuracy: 0.5175\n",
      "Epoch 35/100\n",
      "25724/25724 [==============================] - 4s 169us/sample - loss: 0.7041 - accuracy: 0.5321\n",
      "Epoch 36/100\n",
      "25724/25724 [==============================] - 4s 139us/sample - loss: 0.6946 - accuracy: 0.5321\n",
      "Epoch 37/100\n",
      "25724/25724 [==============================] - 4s 154us/sample - loss: 0.6916 - accuracy: 0.5321\n",
      "Epoch 38/100\n",
      "25724/25724 [==============================] - 5s 184us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 39/100\n",
      "25724/25724 [==============================] - 4s 170us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 40/100\n",
      "25724/25724 [==============================] - 4s 144us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 41/100\n",
      "25724/25724 [==============================] - 4s 167us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 42/100\n",
      "25724/25724 [==============================] - 4s 142us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 43/100\n",
      "25724/25724 [==============================] - 5s 185us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 44/100\n",
      "25724/25724 [==============================] - 5s 212us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 45/100\n",
      "25724/25724 [==============================] - 6s 221us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 46/100\n",
      "25724/25724 [==============================] - 6s 239us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 47/100\n",
      "25724/25724 [==============================] - 5s 213us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 48/100\n",
      "25724/25724 [==============================] - 5s 204us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 49/100\n",
      "25724/25724 [==============================] - 5s 195us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 50/100\n",
      "25724/25724 [==============================] - 5s 201us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 51/100\n",
      "25724/25724 [==============================] - 8s 309us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 52/100\n",
      "25724/25724 [==============================] - 6s 251us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 53/100\n",
      "25724/25724 [==============================] - 4s 157us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 54/100\n",
      "25724/25724 [==============================] - 4s 152us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 55/100\n",
      " 3360/25724 [==>...........................] - ETA: 3s - loss: 0.6892 - accuracy: 0.5467"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train,y_train,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Change Input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EIN</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "      <th>AFFILIATION_CompanySponsored</th>\n",
       "      <th>AFFILIATION_Family/Parent</th>\n",
       "      <th>AFFILIATION_Independent</th>\n",
       "      <th>AFFILIATION_National</th>\n",
       "      <th>AFFILIATION_Other</th>\n",
       "      <th>AFFILIATION_Regional</th>\n",
       "      <th>...</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10520599</td>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10531628</td>\n",
       "      <td>1</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10547893</td>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10553066</td>\n",
       "      <td>1</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10556103</td>\n",
       "      <td>1</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        EIN  STATUS  ASK_AMT  IS_SUCCESSFUL  AFFILIATION_CompanySponsored  \\\n",
       "0  10520599       1     5000              1                           0.0   \n",
       "1  10531628       1   108590              1                           0.0   \n",
       "2  10547893       1     5000              0                           1.0   \n",
       "3  10553066       1     6692              1                           1.0   \n",
       "4  10556103       1   142590              1                           0.0   \n",
       "\n",
       "   AFFILIATION_Family/Parent  AFFILIATION_Independent  AFFILIATION_National  \\\n",
       "0                        0.0                      1.0                   0.0   \n",
       "1                        0.0                      1.0                   0.0   \n",
       "2                        0.0                      0.0                   0.0   \n",
       "3                        0.0                      0.0                   0.0   \n",
       "4                        0.0                      1.0                   0.0   \n",
       "\n",
       "   AFFILIATION_Other  AFFILIATION_Regional  ...  INCOME_AMT_1-9999  \\\n",
       "0                0.0                   0.0  ...                0.0   \n",
       "1                0.0                   0.0  ...                1.0   \n",
       "2                0.0                   0.0  ...                0.0   \n",
       "3                0.0                   0.0  ...                0.0   \n",
       "4                0.0                   0.0  ...                0.0   \n",
       "\n",
       "   INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  INCOME_AMT_10M-50M  \\\n",
       "0                     0.0                       0.0                 0.0   \n",
       "1                     0.0                       0.0                 0.0   \n",
       "2                     0.0                       0.0                 0.0   \n",
       "3                     1.0                       0.0                 0.0   \n",
       "4                     0.0                       1.0                 0.0   \n",
       "\n",
       "   INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  INCOME_AMT_50M+  \\\n",
       "0               0.0                     0.0              0.0   \n",
       "1               0.0                     0.0              0.0   \n",
       "2               0.0                     0.0              0.0   \n",
       "3               0.0                     0.0              0.0   \n",
       "4               0.0                     0.0              0.0   \n",
       "\n",
       "   INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_N  SPECIAL_CONSIDERATIONS_Y  \n",
       "0                0.0                       1.0                       0.0  \n",
       "1                0.0                       1.0                       0.0  \n",
       "2                0.0                       1.0                       0.0  \n",
       "3                0.0                       1.0                       0.0  \n",
       "4                0.0                       1.0                       0.0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "success_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove special considerations and status input columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = success_df[\"IS_SUCCESSFUL\"].values\n",
    "X1 = success_df.drop([\"IS_SUCCESSFUL\",'SPECIAL_CONSIDERATIONS_N' ,'SPECIAL_CONSIDERATIONS_Y','STATUS'],1).values\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train_r, X_test_r, y_train_r, y_test_r = train_test_split(X1, y, random_state=78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instance\n",
    "scaler_r = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler_r = scaler_r.fit(X_train_r)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaler_1 = X_scaler_r.transform(X_train_r)\n",
    "X_test_scaled_r = X_scaler_r.transform(X_test_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_r[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_45 (Dense)             (None, 8)                 216       \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 5)                 45        \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 267\n",
      "Trainable params: 267\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net\n",
    "number_input_features = len(X_train_r[0])\n",
    "hidden_nodes_layer1 =  8\n",
    "hidden_nodes_layer2 = 5\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\")\n",
    ")\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25724 samples\n",
      "Epoch 1/100\n",
      "25724/25724 [==============================] - 6s 227us/sample - loss: 757570.2741 - accuracy: 0.5005\n",
      "Epoch 2/100\n",
      "25724/25724 [==============================] - 3s 104us/sample - loss: 74624.5520 - accuracy: 0.5018\n",
      "Epoch 3/100\n",
      "25724/25724 [==============================] - 3s 99us/sample - loss: 63604.7068 - accuracy: 0.5046\n",
      "Epoch 4/100\n",
      "25724/25724 [==============================] - 3s 105us/sample - loss: 44938.0895 - accuracy: 0.4965\n",
      "Epoch 5/100\n",
      "25724/25724 [==============================] - 3s 106us/sample - loss: 51588.3239 - accuracy: 0.4986\n",
      "Epoch 6/100\n",
      "25724/25724 [==============================] - 3s 113us/sample - loss: 47206.5203 - accuracy: 0.4982\n",
      "Epoch 7/100\n",
      "25724/25724 [==============================] - 3s 128us/sample - loss: 50607.2571 - accuracy: 0.5043\n",
      "Epoch 8/100\n",
      "25724/25724 [==============================] - 3s 126us/sample - loss: 52930.1717 - accuracy: 0.5065\n",
      "Epoch 9/100\n",
      "25724/25724 [==============================] - 4s 142us/sample - loss: 46239.5432 - accuracy: 0.5046\n",
      "Epoch 10/100\n",
      "25724/25724 [==============================] - 3s 126us/sample - loss: 43462.3575 - accuracy: 0.4979\n",
      "Epoch 11/100\n",
      "25724/25724 [==============================] - 3s 101us/sample - loss: 42171.2063 - accuracy: 0.5031 - los\n",
      "Epoch 12/100\n",
      "25724/25724 [==============================] - 3s 118us/sample - loss: 42635.9856 - accuracy: 0.5046\n",
      "Epoch 13/100\n",
      "25724/25724 [==============================] - 3s 133us/sample - loss: 38507.5641 - accuracy: 0.5033\n",
      "Epoch 14/100\n",
      "25724/25724 [==============================] - 3s 103us/sample - loss: 38197.8193 - accuracy: 0.5018\n",
      "Epoch 15/100\n",
      "25724/25724 [==============================] - 3s 104us/sample - loss: 35874.6955 - accuracy: 0.5047\n",
      "Epoch 16/100\n",
      "25724/25724 [==============================] - 3s 104us/sample - loss: 43650.8003 - accuracy: 0.5040\n",
      "Epoch 17/100\n",
      "25724/25724 [==============================] - 3s 107us/sample - loss: 34286.8211 - accuracy: 0.5054\n",
      "Epoch 18/100\n",
      "25724/25724 [==============================] - 3s 106us/sample - loss: 38228.0222 - accuracy: 0.4996\n",
      "Epoch 19/100\n",
      "25724/25724 [==============================] - 3s 109us/sample - loss: 35316.5795 - accuracy: 0.5056\n",
      "Epoch 20/100\n",
      "25724/25724 [==============================] - 3s 109us/sample - loss: 40555.2646 - accuracy: 0.5019\n",
      "Epoch 21/100\n",
      "25724/25724 [==============================] - 3s 112us/sample - loss: 33051.3947 - accuracy: 0.5027\n",
      "Epoch 22/100\n",
      "25724/25724 [==============================] - 3s 124us/sample - loss: 31013.1388 - accuracy: 0.5054\n",
      "Epoch 23/100\n",
      "25724/25724 [==============================] - 3s 111us/sample - loss: 32962.8361 - accuracy: 0.4952\n",
      "Epoch 24/100\n",
      "25724/25724 [==============================] - 3s 106us/sample - loss: 35081.5461 - accuracy: 0.4997\n",
      "Epoch 25/100\n",
      "25724/25724 [==============================] - 3s 104us/sample - loss: 35079.6441 - accuracy: 0.5022\n",
      "Epoch 26/100\n",
      "25724/25724 [==============================] - 3s 113us/sample - loss: 29495.3917 - accuracy: 0.4988\n",
      "Epoch 27/100\n",
      "25724/25724 [==============================] - 3s 109us/sample - loss: 30508.4667 - accuracy: 0.4983\n",
      "Epoch 28/100\n",
      "25724/25724 [==============================] - 3s 110us/sample - loss: 29818.2837 - accuracy: 0.5021\n",
      "Epoch 29/100\n",
      "25724/25724 [==============================] - 3s 112us/sample - loss: 37404.2242 - accuracy: 0.5012\n",
      "Epoch 30/100\n",
      "25724/25724 [==============================] - 3s 112us/sample - loss: 26936.8969 - accuracy: 0.5026\n",
      "Epoch 31/100\n",
      "25724/25724 [==============================] - 3s 118us/sample - loss: 31704.6194 - accuracy: 0.4996\n",
      "Epoch 32/100\n",
      "25724/25724 [==============================] - 3s 120us/sample - loss: 31159.0419 - accuracy: 0.4973\n",
      "Epoch 33/100\n",
      "25724/25724 [==============================] - 3s 107us/sample - loss: 27801.9090 - accuracy: 0.5000\n",
      "Epoch 34/100\n",
      "25724/25724 [==============================] - 3s 107us/sample - loss: 27639.7556 - accuracy: 0.5006\n",
      "Epoch 35/100\n",
      "25724/25724 [==============================] - 3s 108us/sample - loss: 27565.0232 - accuracy: 0.5061\n",
      "Epoch 36/100\n",
      "25724/25724 [==============================] - 3s 108us/sample - loss: 29899.1039 - accuracy: 0.4977\n",
      "Epoch 37/100\n",
      "25724/25724 [==============================] - 3s 106us/sample - loss: 23749.4585 - accuracy: 0.5050\n",
      "Epoch 38/100\n",
      "25724/25724 [==============================] - 3s 105us/sample - loss: 24377.4114 - accuracy: 0.5014\n",
      "Epoch 39/100\n",
      "25724/25724 [==============================] - 3s 107us/sample - loss: 27634.5839 - accuracy: 0.5027\n",
      "Epoch 40/100\n",
      "25724/25724 [==============================] - 3s 111us/sample - loss: 21587.3627 - accuracy: 0.5003\n",
      "Epoch 41/100\n",
      "25724/25724 [==============================] - 3s 108us/sample - loss: 25910.6730 - accuracy: 0.4977\n",
      "Epoch 42/100\n",
      "25724/25724 [==============================] - 3s 110us/sample - loss: 22650.6666 - accuracy: 0.5063\n",
      "Epoch 43/100\n",
      "25724/25724 [==============================] - 3s 111us/sample - loss: 22272.5122 - accuracy: 0.4990\n",
      "Epoch 44/100\n",
      "25724/25724 [==============================] - 3s 114us/sample - loss: 21093.0070 - accuracy: 0.4972\n",
      "Epoch 45/100\n",
      "25724/25724 [==============================] - 3s 110us/sample - loss: 18791.9679 - accuracy: 0.5020\n",
      "Epoch 46/100\n",
      "25724/25724 [==============================] - 3s 111us/sample - loss: 17898.0410 - accuracy: 0.5026\n",
      "Epoch 47/100\n",
      "25724/25724 [==============================] - 3s 112us/sample - loss: 19273.1706 - accuracy: 0.4942\n",
      "Epoch 48/100\n",
      "25724/25724 [==============================] - 3s 110us/sample - loss: 20135.6769 - accuracy: 0.5055\n",
      "Epoch 49/100\n",
      "25724/25724 [==============================] - 3s 112us/sample - loss: 18159.9285 - accuracy: 0.4988 - loss: 16002.6506 - \n",
      "Epoch 50/100\n",
      "25724/25724 [==============================] - 3s 109us/sample - loss: 20128.8218 - accuracy: 0.5000\n",
      "Epoch 51/100\n",
      "25724/25724 [==============================] - 3s 109us/sample - loss: 17749.7474 - accuracy: 0.5019\n",
      "Epoch 52/100\n",
      "25724/25724 [==============================] - 3s 102us/sample - loss: 15365.1732 - accuracy: 0.5024\n",
      "Epoch 53/100\n",
      "25724/25724 [==============================] - 3s 100us/sample - loss: 14880.5841 - accuracy: 0.5074\n",
      "Epoch 54/100\n",
      "25724/25724 [==============================] - 3s 126us/sample - loss: 14915.3670 - accuracy: 0.4995\n",
      "Epoch 55/100\n",
      "25724/25724 [==============================] - 3s 102us/sample - loss: 14633.2616 - accuracy: 0.4984\n",
      "Epoch 56/100\n",
      "25724/25724 [==============================] - 3s 101us/sample - loss: 15363.0660 - accuracy: 0.5004\n",
      "Epoch 57/100\n",
      "25724/25724 [==============================] - 3s 103us/sample - loss: 11725.5295 - accuracy: 0.5024\n",
      "Epoch 58/100\n",
      "25724/25724 [==============================] - 3s 118us/sample - loss: 11658.6546 - accuracy: 0.5039\n",
      "Epoch 59/100\n",
      "25724/25724 [==============================] - 3s 123us/sample - loss: 11524.8820 - accuracy: 0.5037\n",
      "Epoch 60/100\n",
      "25724/25724 [==============================] - 3s 126us/sample - loss: 10637.1615 - accuracy: 0.5007\n",
      "Epoch 61/100\n",
      "25724/25724 [==============================] - 4s 146us/sample - loss: 10602.8742 - accuracy: 0.5026\n",
      "Epoch 62/100\n",
      "25724/25724 [==============================] - 3s 124us/sample - loss: 8522.7081 - accuracy: 0.5007\n",
      "Epoch 63/100\n",
      "25724/25724 [==============================] - 3s 112us/sample - loss: 9367.0620 - accuracy: 0.5015\n",
      "Epoch 64/100\n",
      "25724/25724 [==============================] - 3s 119us/sample - loss: 7425.6869 - accuracy: 0.4986\n",
      "Epoch 65/100\n",
      "25724/25724 [==============================] - 3s 111us/sample - loss: 5489.7084 - accuracy: 0.5067\n",
      "Epoch 66/100\n",
      "25724/25724 [==============================] - 3s 120us/sample - loss: 5495.7664 - accuracy: 0.5023\n",
      "Epoch 67/100\n",
      "25724/25724 [==============================] - 3s 105us/sample - loss: 3682.8663 - accuracy: 0.5037\n",
      "Epoch 68/100\n",
      "25724/25724 [==============================] - 3s 111us/sample - loss: 2941.2338 - accuracy: 0.5068\n",
      "Epoch 69/100\n",
      "25724/25724 [==============================] - 3s 111us/sample - loss: 1520.1751 - accuracy: 0.5035\n",
      "Epoch 70/100\n",
      "25724/25724 [==============================] - 3s 119us/sample - loss: 708.5012 - accuracy: 0.5096\n",
      "Epoch 71/100\n",
      "25724/25724 [==============================] - 3s 120us/sample - loss: 285.2291 - accuracy: 0.5313\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25724/25724 [==============================] - 3s 107us/sample - loss: 397.8906 - accuracy: 0.5110\n",
      "Epoch 73/100\n",
      "25724/25724 [==============================] - 3s 107us/sample - loss: 15.4434 - accuracy: 0.5339\n",
      "Epoch 74/100\n",
      "25724/25724 [==============================] - 3s 110us/sample - loss: 3.5826 - accuracy: 0.5295\n",
      "Epoch 75/100\n",
      "25724/25724 [==============================] - 3s 115us/sample - loss: 0.6977 - accuracy: 0.5321\n",
      "Epoch 76/100\n",
      "25724/25724 [==============================] - 3s 110us/sample - loss: 0.6917 - accuracy: 0.5321\n",
      "Epoch 77/100\n",
      "25724/25724 [==============================] - 3s 105us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 78/100\n",
      "25724/25724 [==============================] - 3s 110us/sample - loss: 0.6911 - accuracy: 0.5321 - los\n",
      "Epoch 79/100\n",
      "25724/25724 [==============================] - 3s 109us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 80/100\n",
      "25724/25724 [==============================] - 3s 104us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 81/100\n",
      "25724/25724 [==============================] - 3s 107us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 82/100\n",
      "25724/25724 [==============================] - 3s 108us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 83/100\n",
      "25724/25724 [==============================] - 3s 105us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 84/100\n",
      "25724/25724 [==============================] - 3s 118us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 85/100\n",
      "25724/25724 [==============================] - 3s 108us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 86/100\n",
      "25724/25724 [==============================] - 3s 106us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 87/100\n",
      "25724/25724 [==============================] - 3s 104us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 88/100\n",
      "25724/25724 [==============================] - 3s 111us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 89/100\n",
      "25724/25724 [==============================] - 3s 121us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 90/100\n",
      "25724/25724 [==============================] - 3s 110us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 91/100\n",
      "25724/25724 [==============================] - 3s 115us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 92/100\n",
      "25724/25724 [==============================] - 3s 110us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 93/100\n",
      "25724/25724 [==============================] - 3s 115us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 94/100\n",
      "25724/25724 [==============================] - 3s 115us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 95/100\n",
      "25724/25724 [==============================] - 3s 114us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 96/100\n",
      "25724/25724 [==============================] - 3s 123us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 97/100\n",
      "25724/25724 [==============================] - 3s 108us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 98/100\n",
      "25724/25724 [==============================] - 3s 102us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 99/100\n",
      "25724/25724 [==============================] - 3s 106us/sample - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 100/100\n",
      "25724/25724 [==============================] - 3s 120us/sample - loss: 0.6911 - accuracy: 0.5321\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train_r,y_train_r,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8575/1 - 1s - loss: 0.6900 - accuracy: 0.5332\n",
      "Loss: 0.6909448554147437, Accuracy: 0.5331778526306152\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_r,y_test_r,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By changing the input data, the accuracy didn't change significantly its almost the same with a 53.38% accuaracy and a 0.6907 loss, whereas the original mosel had an accuracy of 53.32% and loss of 0.691."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Random forest predictive accuracy: 0.664\n"
     ]
    }
   ],
   "source": [
    "# import dependencies\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Create a random forest classifier.\n",
    "rf_model = RandomForestClassifier(n_estimators=128, random_state=78)\n",
    "\n",
    "# Fitting the model\n",
    "rf_model = rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = rf_model.predict(X_test_scaled)\n",
    "print(f\" Random forest predictive accuracy: {accuracy_score(y_test,y_pred):.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python37464bitbasecondae91164462bbc4467b6cbe6ca9ff3d156"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
